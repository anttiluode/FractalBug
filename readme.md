Fractal Bug 

A Hive Mind Adaptive System

"Resistance is futile" 

https://youtu.be/Fcga4oYs4R0

A neural network simulation that combines collective intelligence with bidirectional encoding to create emergent behavior patterns.
Overview
The Hive Mind system creates an adaptive network where multiple layers work together to control movement and behavior. Each layer processes information both forward and backward in time, allowing the system to learn from past experiences while anticipating future states.
Key Features
Bidirectional Processing

Forward encoding: Helps predict future positions and movements
Backward encoding: Maintains context from past experiences
Temporal weighting: Balances past knowledge with future predictions

Collective Decision Making

Multiple network layers contribute to movement
Each layer has its own perspective and influence
Weighted contributions based on layer depth and success
Emergent behavior from layer interactions

Visual Learning

Processes webcam input for visual awareness
Converts visual information into movement decisions
Maintains visual memory for pattern recognition

Interactive Visualization

3D network structure visualization
Movement pattern analysis
Real-time performance monitoring
Layer-specific focus controls

Installation

git clone https://github.com/anttiluode/fractalbug.git

cd fractalbug

# Create a Virtual Environment (Optional but Recommended)

python -m venv venv

source venv/bin/activate  # On Windows: venv\Scripts\activate

# install requirements file 

pip install -r requirements.txt

# Then Run the app

python app.py

Start: Begin the hive mind system
Stop: Pause system operation
Visualize: Open the network visualization window
Configure: Adjust system parameters

Configuration Options

Network structure (nodes, layers)
Learning parameters
Movement speed and responsiveness
Vision settings

Visualization Views

Network Structure: See how layers connect and interact
Movement Patterns: Watch how the system moves and adapts
State Analysis: Monitor learning and performance

How It Works

Input Processing

Camera captures visual information
System extracts relevant features
Information flows through network layers


Decision Making

Each layer processes information bidirectionally
Layers contribute movement suggestions
System combines suggestions into final movement


Learning

Successful movements are reinforced
Network adapts connection strengths
System builds collective memory


Visualization

Real-time display of network activity
Movement tracking and analysis
Performance monitoring



Requirements

Python 3.7+
Webcam
Graphics support for visualization

License
MIT License
This project demonstrates emergent behavior through collective intelligence and bidirectional processing, creating a system that can learn and adapt through experience while maintaining awareness of both past and future states.
